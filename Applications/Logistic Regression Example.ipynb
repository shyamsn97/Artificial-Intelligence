{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_split_set(X,portion,y=None):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    size = int(X.shape[0]*portion)\n",
    "    indexlist = np.arange(X.shape[0])\n",
    "    testinds = np.random.choice(indexlist, size, replace=False)\n",
    "    traininds = np.array([x for x in range(X.shape[0]) if x not in testinds])  \n",
    "    if np.all(y == None):\n",
    "        return X[traininds],X[testinds]\n",
    "    else:\n",
    "        return X[traininds],X[testinds],y[traininds],y[testinds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target\n",
    "indices = np.append(np.where(y==0)[0],np.where(y==1)[0])\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "X_train, X_test, y_train, y_test = cross_val_split_set(X,0.1,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x,derivative=False):\n",
    "\t'''\n",
    "\tsigmoid function, set derivative = true to get the derivative\n",
    "\t'''\n",
    "\tif derivative==True:\n",
    "\t\treturn 1/(1+np.e**-(x*1.0))*(1-(1/(1+np.e**-(x*1.0))))\n",
    "\telse:\n",
    "\t\treturn 1/(1+np.e**-(x*1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batch_Gradient_Descent(X,y,parameters,gradient_func,predict_func,learning_rate=0.001,epochs=200,batch_size=32):\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        h = predict_func(X,parameters)\n",
    "        indices = np.arange(y.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        sample = 0\n",
    "\n",
    "        while(sample < y.shape[0]):\n",
    "\n",
    "            batch_X = X[sample:(sample+batch_size)]\n",
    "            batch_y = y[sample:(sample+batch_size)]\n",
    "            batch_h = h[sample:(sample+batch_size)]\n",
    "            sample += batch_size\n",
    "\n",
    "            parameters = parameters - learning_rate*gradient_func(parameters,batch_X,batch_y)\n",
    "            \n",
    "        print(\"EPOCHS: \" + str(i))\n",
    "                   \n",
    "    return parameters \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../tools')\n",
    "import tools\n",
    "import iterative_methods\n",
    "\n",
    "class LogisticRegression():\n",
    "    \n",
    "    def __init__(self,X,y):\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.weights = np.random.uniform(10,size=X.shape[1])\n",
    "        \n",
    "    def gradient_func(self,parameters,X,y):\n",
    "        \n",
    "        h = self.predict(X,parameters)\n",
    "        return (X.T.dot(h-y))\n",
    "    \n",
    "    def predict(self,X,parameters = 0):\n",
    "        \n",
    "        if np.all(parameters == 0):\n",
    "            parameters = self.weights\n",
    "            predictions = tools.sigmoid(X.dot(parameters)).astype(float)\n",
    "            predictions[predictions > 0.5] = 1\n",
    "            predictions[predictions <= 0.5] = 0\n",
    "            return predictions\n",
    "        return tools.sigmoid(X.dot(parameters)).astype(float)\n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        self.weights = iterative_methods.Batch_Gradient_Descent(self.X,self.y,self.weights,self.gradient_func,self.predict)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones(X_train.shape[0]).reshape(X_train.shape[0],1).astype(float)\n",
    "X_train = np.column_stack((ones,X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS: 0\n",
      "EPOCHS: 1\n",
      "EPOCHS: 2\n",
      "EPOCHS: 3\n",
      "EPOCHS: 4\n",
      "EPOCHS: 5\n",
      "EPOCHS: 6\n",
      "EPOCHS: 7\n",
      "EPOCHS: 8\n",
      "EPOCHS: 9\n",
      "EPOCHS: 10\n",
      "EPOCHS: 11\n",
      "EPOCHS: 12\n",
      "EPOCHS: 13\n",
      "EPOCHS: 14\n",
      "EPOCHS: 15\n",
      "EPOCHS: 16\n",
      "EPOCHS: 17\n",
      "EPOCHS: 18\n",
      "EPOCHS: 19\n",
      "EPOCHS: 20\n",
      "EPOCHS: 21\n",
      "EPOCHS: 22\n",
      "EPOCHS: 23\n",
      "EPOCHS: 24\n",
      "EPOCHS: 25\n",
      "EPOCHS: 26\n",
      "EPOCHS: 27\n",
      "EPOCHS: 28\n",
      "EPOCHS: 29\n",
      "EPOCHS: 30\n",
      "EPOCHS: 31\n",
      "EPOCHS: 32\n",
      "EPOCHS: 33\n",
      "EPOCHS: 34\n",
      "EPOCHS: 35\n",
      "EPOCHS: 36\n",
      "EPOCHS: 37\n",
      "EPOCHS: 38\n",
      "EPOCHS: 39\n",
      "EPOCHS: 40\n",
      "EPOCHS: 41\n",
      "EPOCHS: 42\n",
      "EPOCHS: 43\n",
      "EPOCHS: 44\n",
      "EPOCHS: 45\n",
      "EPOCHS: 46\n",
      "EPOCHS: 47\n",
      "EPOCHS: 48\n",
      "EPOCHS: 49\n",
      "EPOCHS: 50\n",
      "EPOCHS: 51\n",
      "EPOCHS: 52\n",
      "EPOCHS: 53\n",
      "EPOCHS: 54\n",
      "EPOCHS: 55\n",
      "EPOCHS: 56\n",
      "EPOCHS: 57\n",
      "EPOCHS: 58\n",
      "EPOCHS: 59\n",
      "EPOCHS: 60\n",
      "EPOCHS: 61\n",
      "EPOCHS: 62\n",
      "EPOCHS: 63\n",
      "EPOCHS: 64\n",
      "EPOCHS: 65\n",
      "EPOCHS: 66\n",
      "EPOCHS: 67\n",
      "EPOCHS: 68\n",
      "EPOCHS: 69\n",
      "EPOCHS: 70\n",
      "EPOCHS: 71\n",
      "EPOCHS: 72\n",
      "EPOCHS: 73\n",
      "EPOCHS: 74\n",
      "EPOCHS: 75\n",
      "EPOCHS: 76\n",
      "EPOCHS: 77\n",
      "EPOCHS: 78\n",
      "EPOCHS: 79\n",
      "EPOCHS: 80\n",
      "EPOCHS: 81\n",
      "EPOCHS: 82\n",
      "EPOCHS: 83\n",
      "EPOCHS: 84\n",
      "EPOCHS: 85\n",
      "EPOCHS: 86\n",
      "EPOCHS: 87\n",
      "EPOCHS: 88\n",
      "EPOCHS: 89\n",
      "EPOCHS: 90\n",
      "EPOCHS: 91\n",
      "EPOCHS: 92\n",
      "EPOCHS: 93\n",
      "EPOCHS: 94\n",
      "EPOCHS: 95\n",
      "EPOCHS: 96\n",
      "EPOCHS: 97\n",
      "EPOCHS: 98\n",
      "EPOCHS: 99\n",
      "EPOCHS: 100\n",
      "EPOCHS: 101\n",
      "EPOCHS: 102\n",
      "EPOCHS: 103\n",
      "EPOCHS: 104\n",
      "EPOCHS: 105\n",
      "EPOCHS: 106\n",
      "EPOCHS: 107\n",
      "EPOCHS: 108\n",
      "EPOCHS: 109\n",
      "EPOCHS: 110\n",
      "EPOCHS: 111\n",
      "EPOCHS: 112\n",
      "EPOCHS: 113\n",
      "EPOCHS: 114\n",
      "EPOCHS: 115\n",
      "EPOCHS: 116\n",
      "EPOCHS: 117\n",
      "EPOCHS: 118\n",
      "EPOCHS: 119\n",
      "EPOCHS: 120\n",
      "EPOCHS: 121\n",
      "EPOCHS: 122\n",
      "EPOCHS: 123\n",
      "EPOCHS: 124\n",
      "EPOCHS: 125\n",
      "EPOCHS: 126\n",
      "EPOCHS: 127\n",
      "EPOCHS: 128\n",
      "EPOCHS: 129\n",
      "EPOCHS: 130\n",
      "EPOCHS: 131\n",
      "EPOCHS: 132\n",
      "EPOCHS: 133\n",
      "EPOCHS: 134\n",
      "EPOCHS: 135\n",
      "EPOCHS: 136\n",
      "EPOCHS: 137\n",
      "EPOCHS: 138\n",
      "EPOCHS: 139\n",
      "EPOCHS: 140\n",
      "EPOCHS: 141\n",
      "EPOCHS: 142\n",
      "EPOCHS: 143\n",
      "EPOCHS: 144\n",
      "EPOCHS: 145\n",
      "EPOCHS: 146\n",
      "EPOCHS: 147\n",
      "EPOCHS: 148\n",
      "EPOCHS: 149\n",
      "EPOCHS: 150\n",
      "EPOCHS: 151\n",
      "EPOCHS: 152\n",
      "EPOCHS: 153\n",
      "EPOCHS: 154\n",
      "EPOCHS: 155\n",
      "EPOCHS: 156\n",
      "EPOCHS: 157\n",
      "EPOCHS: 158\n",
      "EPOCHS: 159\n",
      "EPOCHS: 160\n",
      "EPOCHS: 161\n",
      "EPOCHS: 162\n",
      "EPOCHS: 163\n",
      "EPOCHS: 164\n",
      "EPOCHS: 165\n",
      "EPOCHS: 166\n",
      "EPOCHS: 167\n",
      "EPOCHS: 168\n",
      "EPOCHS: 169\n",
      "EPOCHS: 170\n",
      "EPOCHS: 171\n",
      "EPOCHS: 172\n",
      "EPOCHS: 173\n",
      "EPOCHS: 174\n",
      "EPOCHS: 175\n",
      "EPOCHS: 176\n",
      "EPOCHS: 177\n",
      "EPOCHS: 178\n",
      "EPOCHS: 179\n",
      "EPOCHS: 180\n",
      "EPOCHS: 181\n",
      "EPOCHS: 182\n",
      "EPOCHS: 183\n",
      "EPOCHS: 184\n",
      "EPOCHS: 185\n",
      "EPOCHS: 186\n",
      "EPOCHS: 187\n",
      "EPOCHS: 188\n",
      "EPOCHS: 189\n",
      "EPOCHS: 190\n",
      "EPOCHS: 191\n",
      "EPOCHS: 192\n",
      "EPOCHS: 193\n",
      "EPOCHS: 194\n",
      "EPOCHS: 195\n",
      "EPOCHS: 196\n",
      "EPOCHS: 197\n",
      "EPOCHS: 198\n",
      "EPOCHS: 199\n"
     ]
    }
   ],
   "source": [
    "lr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones(X_test.shape[0]).reshape(X_test.shape[0],1)\n",
    "X_test = np.column_stack((ones,X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 1., 1., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(obj,xtest,ytest):\n",
    "    predictions = obj.predict(xtest)\n",
    "    acc = ytest - predictions\n",
    "    return np.where(acc == 0)[0].shape[0]/ytest.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = y_test - predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy(lr,X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
